{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import Compose, functional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import dill\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
    "from pyro.infer import Predictive, Trace_ELBO\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding sentiment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COLS = 3\n",
    "INPUT_SHAPE = [10,3]\n",
    "INPUT_SIZE = 5\n",
    "Z_DIM = 200\n",
    "DATA_PATH ='/home/flor/cs236/data/d_dfs.pkd'\n",
    "NN_PREDICTIONS_PATH = '/home/flor/cs236/data/predictions_baseline_norm_input55.pkd'\n",
    "CVAE_PREDICTIONS_PATH = '/home/flor/cs236/data/predictions_cvae_norm_input55.pkd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STOCK(Dataset):\n",
    "    def __init__(self, pd_df, input_size = INPUT_SIZE, mask_size=5, n_cols=N_COLS, train = True):\n",
    "        self.ncols = n_cols\n",
    "        self.original, self.test_low, self.test_high, self.minmax = self.loadData(pd_df, input_size, mask_size)\n",
    "        self.transform =  Compose([ToTensor(), MaskData(pos=mask_size)])\n",
    "        self.train = train\n",
    "    def __len__(self):\n",
    "        return len(self.original)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sample = {\"original\":self.original[item]}\n",
    "        test_low = {\"original\":self.test_low[0]}\n",
    "        test_high = {\"original\":self.test_high[0]}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            test_low = self.transform(test_low)\n",
    "            test_high = self.transform(test_high)\n",
    "        if self.train:\n",
    "            return sample\n",
    "        else:\n",
    "            return {'input_low': test_low['input'], 'input_high': test_high['input']}\n",
    "    \n",
    "    def loadData(self, df, input_size, mask_size):\n",
    "    \n",
    "        minmax = StandardScaler().fit(df[['close','high','low']].values.reshape(-1,3))\n",
    "        df_norm = pd.DataFrame(minmax.transform(df[['close','high','low']].values).reshape(-1,3))\n",
    "        \n",
    "        df_norm.index = df.index\n",
    "        df_norm.columns = df.columns\n",
    "   \n",
    "        #add_cols = []\n",
    "        #if self.ncols > 3:\n",
    "        #    add_cols = ['relevance_score','ticker_sentiment_score' ]\n",
    "        #    for col in add_cols:\n",
    "        #        df_norm[col] = (df[col] + 1)/2\n",
    "        #    df_norm['sentiment'] =(df['relevance_score']*df['ticker_sentiment_score']+1)/2\n",
    "\n",
    "        dataset = []\n",
    "        for i in range(len(df_norm) - (input_size+mask_size) - 1):\n",
    "            dataset.append(df_norm.iloc[i:i + (input_size+mask_size),:])\n",
    "        \n",
    "        testset_low = [pd.concat([df_norm.iloc[-(input_size+mask_size-1) : -1],pd.DataFrame(\n",
    "            [dict(zip(df_norm.columns,[0]*len(df_norm.columns)))]*2)])]\n",
    "        \n",
    "        testset_high = [pd.concat([df_norm.iloc[-input_size : ]\n",
    "                        ,pd.DataFrame([dict(zip(df_norm.columns\n",
    "                                                ,[0]*len(df_norm.columns)))]*mask_size)])]\n",
    "\n",
    "        return dataset, testset_low, testset_high, minmax\n",
    "    \n",
    "    def reverseMinMax(self, pred):\n",
    "        return self.minmax.inverse_transform(pred)\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        sample['original'] = torch.from_numpy(sample['original'].values).float()\n",
    "        return sample\n",
    "\n",
    "class MaskData:\n",
    "    \"\"\"This transformation masks the values to be predicted with -1 and\n",
    "    adds the target output in the sample dict as the complementary of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pos=1, mask_with=-1):\n",
    "        self.mask_with = mask_with\n",
    "        self.pos = -pos\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        tensor = sample['original']\n",
    "        inp = tensor.detach().clone()\n",
    "\n",
    "        # remove the last one\n",
    "        inp[self.pos:] = self.mask_with\n",
    "\n",
    "        # now, sets the input as complementary\n",
    "        out = tensor.clone()\n",
    "        out[inp != -1] = self.mask_with\n",
    "\n",
    "        sample[\"input\"] = inp\n",
    "        sample[\"output\"] = out\n",
    "        \n",
    "        # Remove the sentiment from output so that we dont calculate loss for it.\n",
    "        #out[self.pos:, 3:] = -1\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, batch_size=16):\n",
    "    data, dl, ds = {}, {}, {}\n",
    "    data['train'] = STOCK(df)\n",
    "    data['test'] = STOCK(df, train = False)\n",
    "    dl['train'] = DataLoader(data['train'], batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    dl['val'] = DataLoader(data['train'], batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    ds['train'] = ds['val'] = len(dl['train'])\n",
    "    return data, dl, ds\n",
    "\n",
    "def get_all_data(filepath = DATA_PATH):\n",
    "    datasets, dataloaders, dataset_sizes = defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "    d_all = pd.read_pickle(filepath)\n",
    "    for ticker, dates in d_all.items():    \n",
    "        for date,df in dates.items():\n",
    "            prev_close = df['close'].shift(fill_value=0)\n",
    "            df['high'] = df['high'] - prev_close\n",
    "            df['low'] = df['low'] - prev_close\n",
    "            df['close'] = df['close'] - prev_close\n",
    "            df = df.iloc[1:]\n",
    "            datasets[ticker][date], dataloaders[ticker][date], dataset_sizes[ticker][date] = get_data(df)\n",
    "    return datasets, dataloaders, dataset_sizes\n",
    "\n",
    "datasets, dataloaders, dataset_sizes = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': tensor([[-5.6789e-01,  2.2252e-01,  9.6269e-02],\n",
       "         [ 1.5953e-01, -1.2777e-01, -1.4049e+00],\n",
       "         [-1.3405e+00, -1.2184e-01, -9.9828e-01],\n",
       "         [ 9.5317e-01,  8.9191e-01,  1.5871e+00],\n",
       "         [ 9.1103e-01,  9.0981e-01,  1.4361e+00],\n",
       "         [-1.8662e-01, -6.8635e-01,  1.8825e-02],\n",
       "         [-6.8528e-01, -8.2686e-01, -2.6514e-01],\n",
       "         [ 1.3585e+00,  1.2956e+00,  5.3254e-01],\n",
       "         [ 1.8833e+00,  2.0185e+00,  1.1999e+00],\n",
       "         [ 2.0769e-01, -4.4541e-01, -5.2373e-04]]),\n",
       " 'input': tensor([[-0.5679,  0.2225,  0.0963],\n",
       "         [ 0.1595, -0.1278, -1.4049],\n",
       "         [-1.3405, -0.1218, -0.9983],\n",
       "         [ 0.9532,  0.8919,  1.5871],\n",
       "         [ 0.9110,  0.9098,  1.4361],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]]),\n",
       " 'output': tensor([[-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "         [-1.8662e-01, -6.8635e-01,  1.8825e-02],\n",
       "         [-6.8528e-01, -8.2686e-01, -2.6514e-01],\n",
       "         [ 1.3585e+00,  1.2956e+00,  5.3254e-01],\n",
       "         [ 1.8833e+00,  2.0185e+00,  1.1999e+00],\n",
       "         [ 2.0769e-01, -4.4541e-01, -5.2373e-04]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['COST'][datetime(2022, 10, 27)]['train'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_low': tensor([[ 0.9532,  0.8919,  1.5871],\n",
       "         [ 0.9110,  0.9098,  1.4361],\n",
       "         [-0.1866, -0.6863,  0.0188],\n",
       "         [-0.6853, -0.8269, -0.2651],\n",
       "         [ 1.3585,  1.2956,  0.5325],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]]),\n",
       " 'input_high': tensor([[ 1.3585e+00,  1.2956e+00,  5.3254e-01],\n",
       "         [ 1.8833e+00,  2.0185e+00,  1.1999e+00],\n",
       "         [ 2.0769e-01, -4.4541e-01, -5.2373e-04],\n",
       "         [ 3.7124e-02,  3.1751e-01,  3.9959e-01],\n",
       "         [-2.9398e-01, -3.9494e-01,  1.4919e-01],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "         [-1.0000e+00, -1.0000e+00, -1.0000e+00]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['COST'][datetime(2022, 10, 27)]['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, hidden_1, hidden_2, input_shape=INPUT_SHAPE):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(np.prod(input_shape), hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, np.prod(input_shape))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, np.prod(self.input_shape))\n",
    "        hidden = self.relu(self.fc1(x))\n",
    "        hidden = self.relu(self.fc2(hidden))\n",
    "        y = torch.sigmoid(self.fc3(hidden))\n",
    "        return y\n",
    "\n",
    "\n",
    "class MaskedMSELoss(nn.Module):\n",
    "    def __init__(self, masked_with=-1):\n",
    "        super().__init__()\n",
    "        self.masked_with = masked_with\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        target = target.view(input.shape)\n",
    "        loss = F.mse_loss(input, target, reduction=\"none\")\n",
    "        loss[target == self.masked_with] = 0\n",
    "        return loss.sum()\n",
    "\n",
    "\n",
    "def train_baseline(\n",
    "    device,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    learning_rate,\n",
    "    num_epochs,\n",
    "    early_stop_patience,\n",
    "    model_path=None,\n",
    "    input_shape = INPUT_SHAPE\n",
    "):\n",
    "    # Train baseline\n",
    "    baseline_net = BaselineNet(500, 500,input_shape=input_shape)\n",
    "    baseline_net.to(device)\n",
    "    optimizer = torch.optim.Adam(baseline_net.parameters(), lr=learning_rate)\n",
    "    criterion = MaskedMSELoss()\n",
    "    best_loss = np.inf\n",
    "    early_stop_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                baseline_net.train()\n",
    "            else:\n",
    "                baseline_net.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            num_preds = 0\n",
    "\n",
    "            #bar = tqdm(dataloaders[phase], desc=\"NN Epoch {} {}\".format(epoch, phase).ljust(20))\n",
    "\n",
    "            #for i, batch in enumerate(bar):\n",
    "            for batch in dataloaders[phase]:#don't want 100 epoch bars for each of hundreds of models\n",
    "                inputs = batch[\"input\"].to(device)\n",
    "                outputs = batch[\"output\"].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    preds = baseline_net(inputs)\n",
    "                    loss = criterion(preds, outputs) / inputs.size(0)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                num_preds += 1\n",
    "                #if i % 10 == 0:\n",
    "                #    bar.set_postfix(\n",
    "                #        loss=\"{:.2f}\".format(running_loss / num_preds),\n",
    "                #        early_stop_count=early_stop_count,\n",
    "                #    )\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # deep copy the model\n",
    "            if phase == \"val\":\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(baseline_net.state_dict())\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= early_stop_patience:\n",
    "            break\n",
    "\n",
    "    baseline_net.load_state_dict(best_model_wts)\n",
    "    baseline_net.eval()\n",
    "\n",
    "    # Save model weights\n",
    "    #Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    #torch.save(baseline_net.state_dict(), model_path)\n",
    "\n",
    "    return baseline_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_net = train_baseline(device=torch.device(\n",
    "        \"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            dataloaders=dataloaders['COST'][datetime(2022, 10, 27)],\n",
    "            dataset_sizes=dataset_sizes['COST'][datetime(2022, 10, 27)],\n",
    "            learning_rate=1.0e-3,\n",
    "            num_epochs=101,\n",
    "            early_stop_patience=20,\n",
    "            model_path=\"baseline_net1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_1, hidden_2, input_shape=INPUT_SHAPE):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(np.prod(input_shape), hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc31 = nn.Linear(hidden_2, z_dim)\n",
    "        self.fc32 = nn.Linear(hidden_2, z_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # put x and y together in the same tensor for simplification\n",
    "        xc = x.clone()\n",
    "        xc[x == -1] = y[x == -1]\n",
    "        xc = xc.view(-1, np.prod(self.input_shape))\n",
    "        # then compute the hidden units\n",
    "        hidden = self.relu(self.fc1(xc))\n",
    "        hidden = self.relu(self.fc2(hidden))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc31(hidden)\n",
    "        z_scale = torch.exp(self.fc32(hidden))\n",
    "        return z_loc, z_scale\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_1, hidden_2,  input_shape=INPUT_SHAPE):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, np.prod(input_shape))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, z):\n",
    "        y = self.relu(self.fc1(z))\n",
    "        y = self.relu(self.fc2(y))\n",
    "        y = torch.sigmoid(self.fc3(y))\n",
    "        #y = self.fc3(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_1, hidden_2, pre_trained_baseline_net,  input_shape=INPUT_SHAPE):\n",
    "        super().__init__()\n",
    "        # The CVAE is composed of multiple MLPs, such as recognition network\n",
    "        # qφ(z|x, y), (conditional) prior network pθ(z|x), and generation\n",
    "        # network pθ(y|x, z). Also, CVAE is built on top of the NN: not only\n",
    "        # the direct input x, but also the initial guess y_hat made by the NN\n",
    "        # are fed into the prior network.\n",
    "        self.baseline_net = pre_trained_baseline_net\n",
    "        self.prior_net = Encoder(z_dim, hidden_1, hidden_2)\n",
    "        self.generation_net = Decoder(z_dim, hidden_1, hidden_2)\n",
    "        self.recognition_net = Encoder(z_dim, hidden_1, hidden_2)\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def model(self, xs, ys=None):\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"generation_net\", self)\n",
    "        batch_size = xs.shape[0]\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            # Prior network uses the baseline predictions as initial guess.\n",
    "            # This is the generative process with recurrent connection\n",
    "            with torch.no_grad():\n",
    "                # this ensures the training process does not change the\n",
    "                # baseline network\n",
    "                y_hat = self.baseline_net(xs).view(xs.shape)\n",
    "\n",
    "            # sample the handwriting style from the prior distribution, which is\n",
    "            # modulated by the input xs.\n",
    "            prior_loc, prior_scale = self.prior_net(xs, y_hat)\n",
    "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
    "\n",
    "            # the output y is generated from the distribution pθ(y|x, z)\n",
    "            loc = self.generation_net(zs)\n",
    "\n",
    "            if ys is not None:\n",
    "                # In training, we will only sample in the masked image\n",
    "                mask_loc = loc[(xs == -1).view(-1, np.prod(self.input_shape))].view(batch_size, -1)\n",
    "                mask_ys = ys[xs == -1].view(batch_size, -1)\n",
    "                \n",
    "                pyro.deterministic(\"y\", loc)\n",
    "\n",
    "            else:\n",
    "                # In testing, no need to sample: the output is already a\n",
    "                # probability in [0, 1] range, which better represent pixel\n",
    "                # values considering grayscale. If we sample, we will force\n",
    "                # each pixel to be  either 0 or 1, killing the grayscale\n",
    "                pyro.deterministic(\"y\", loc.detach())\n",
    "\n",
    "            # return the loc so we can visualize it later\n",
    "            return loc\n",
    "\n",
    "    def guide(self, xs, ys=None):\n",
    "        with pyro.plate(\"data\"):\n",
    "            if ys is None:\n",
    "                # at inference time, ys is not provided. In that case,\n",
    "                # the model uses the prior network\n",
    "                y_hat = self.baseline_net(xs).view(xs.shape)\n",
    "                loc, scale = self.prior_net(xs, y_hat)\n",
    "            else:\n",
    "                # at training time, uses the variational distribution\n",
    "                # q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
    "                loc, scale = self.recognition_net(xs, ys)\n",
    "            \n",
    "            pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
    "\n",
    "\n",
    "def train_cvae(\n",
    "    device,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    learning_rate,\n",
    "    num_epochs,\n",
    "    early_stop_patience,\n",
    "    model_path=\"cvae_net1.pth\",\n",
    "    pre_trained_baseline_net=baseline_net,\n",
    "):\n",
    "    # clear param store\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    cvae_net = CVAE(Z_DIM, 500, 500, pre_trained_baseline_net)\n",
    "    cvae_net.to(device)\n",
    "    optimizer = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "    svi = SVI(cvae_net.model, cvae_net.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "    best_loss = np.inf\n",
    "    early_stop_count = 0\n",
    "    Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            running_loss = 0.0\n",
    "            num_preds = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            #bar = tqdm(\n",
    "            #    dataloaders[phase],\n",
    "            #    desc=\"CVAE Epoch {} {}\".format(epoch, phase).ljust(20))\n",
    "            #for i,batch in enumerate(bar):\n",
    "            for batch in dataloaders[phase]:#don't want epoch bars for hundreds of models\n",
    "                inputs = batch[\"input\"].to(device)\n",
    "                outputs = batch[\"output\"].to(device)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss = svi.step(inputs, outputs)\n",
    "                else:\n",
    "                    loss = svi.evaluate_loss(inputs, outputs)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss / inputs.size(0)\n",
    "                num_preds += 1\n",
    "                #if i % 10 == 0:\n",
    "                #    bar.set_postfix(\n",
    "                #        loss=\"{:.2f}\".format(running_loss / num_preds),\n",
    "                #        early_stop_count=early_stop_count)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # deep copy the model\n",
    "            if phase == \"val\":\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    torch.save(cvae_net.state_dict(), model_path)\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= early_stop_patience:\n",
    "            break\n",
    "\n",
    "    # Save model weights\n",
    "    cvae_net.load_state_dict(torch.load(model_path))\n",
    "    cvae_net.eval()\n",
    "    return cvae_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_net = train_cvae(\n",
    "            device=torch.device(\n",
    "        \"cuda:0\" if torch.cuda.is_available() and args.cuda else \"cpu\"),\n",
    "            dataloaders=dataloaders['COST'][datetime(2022, 10, 27)],\n",
    "            dataset_sizes=dataset_sizes['COST'][datetime(2022, 10, 27)],\n",
    "            learning_rate=1.0e-3,\n",
    "            num_epochs=101,\n",
    "            early_stop_patience=20,\n",
    "            model_path=\"cvae_net.pth\",\n",
    "            pre_trained_baseline_net=baseline_net,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COST 2022-10-27 00:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-85f724113919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0md_baseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_cvae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-85f724113919>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0md_baseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_cvae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_baseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN_PREDICTIONS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_cvae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCVAE_PREDICTIONS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-85f724113919>\u001b[0m in \u001b[0;36mtrain_predict\u001b[0;34m(ticker, date, device, mask_shape)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             early_stop_patience=20)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0md_baseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'low'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_baseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimated_high'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input_low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprelim_high_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f85fe96ba3d0>\u001b[0m in \u001b[0;36mtrain_baseline\u001b[0;34m(device, dataloaders, dataset_sizes, learning_rate, num_epochs, early_stop_patience, model_path, input_shape)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m#for i, batch in enumerate(bar):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#don't want 100 epoch bars for each of hundreds of models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a802528c97ea>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtest_low\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_low\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtest_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_high\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a802528c97ea>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_predict(ticker, date\n",
    "        , device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), mask_shape=[INPUT_SIZE,3]):\n",
    "    d_baseline, d_cvae = {}, {}\n",
    "    dataset = datasets[ticker][date]\n",
    "    dataloader_test = DataLoader(dataset[\"test\"], batch_size=1, shuffle=False)\n",
    "    batch = next(iter(dataloader_test))\n",
    "    \n",
    "    def get_pred(model, input_type, prelim_high_prediction=False):\n",
    "        ### input_type: input_low or input_high\n",
    "        print(batch[input_type])\n",
    "        prediction = model(batch[input_type].to(device))\n",
    "        if type(prediction) == dict:\n",
    "            prediction = prediction['y']\n",
    "        prediction = prediction.reshape(-1,N_COLS).detach()\n",
    "        \n",
    "        prediction = torch.from_numpy(dataset['test'].reverseMinMax(prediction[:,:3]))\n",
    "        index = {'input_low':2, 'input_high':1}\n",
    "        if input_type == 'input_low' and prelim_high_prediction:\n",
    "            return prediction[mask_shape[0], index['input_low']].item()\\\n",
    "                    , prediction[mask_shape[0]+mask_shape[1]-1, index['input_high']].item()\n",
    "        return prediction[mask_shape[0], index[input_type]].item(),0\n",
    "    \n",
    "    baseline_net = train_baseline(device=device,\n",
    "            dataloaders=dataloaders[ticker][date],\n",
    "            dataset_sizes=dataset_sizes[ticker][date],\n",
    "            learning_rate=1.0e-3,\n",
    "            num_epochs=101,\n",
    "            early_stop_patience=20)\n",
    "\n",
    "    d_baseline['low'], d_baseline['estimated_high'] = get_pred(baseline_net, 'input_low', prelim_high_prediction = True)\n",
    "    d_baseline['high'] = get_pred(baseline_net, 'input_high')[0]\n",
    "    \n",
    "    cvae_net = train_cvae(device,\n",
    "            dataloaders=dataloaders[ticker][date],\n",
    "            dataset_sizes=dataset_sizes[ticker][date],\n",
    "            learning_rate=1.0e-3,\n",
    "            num_epochs=101,\n",
    "            early_stop_patience=20,\n",
    "            pre_trained_baseline_net=baseline_net,)\n",
    "    predictive = Predictive(cvae_net.model, guide=cvae_net.guide, num_samples=1)\n",
    "\n",
    "    d_cvae['low'], d_cvae['estimated_high'] = get_pred(predictive, 'input_low' , prelim_high_prediction = True)\n",
    "    d_cvae['high'] = get_pred(predictive, 'input_high')[0]\n",
    "\n",
    "    return d_baseline,d_cvae\n",
    "\n",
    "def get_predictions():\n",
    "    d_all = pd.read_pickle(DATA_PATH)\n",
    "    d_baseline, d_cvae = defaultdict(dict), defaultdict(dict)\n",
    "    d_base_temp, d_cvae_temp = {}, {}\n",
    "    for ticker, dates in d_all.items():\n",
    "        for date,df in dates.items():\n",
    "            print(ticker,date)\n",
    "            d_base_temp, d_cvae_temp = train_predict(ticker, date)\n",
    "            d_base_temp['high'] = d_base_temp['high'] + df.iloc[-1]['close']\n",
    "            d_cvae_temp['high'] = d_cvae_temp['high'] + df.iloc[-1]['close']\n",
    "            d_cvae_temp['estimated_high'] = d_cvae_temp['estimated_high'] + df.iloc[-1]['close']\n",
    "            d_base_temp['low'] = d_base_temp['low'] + df.iloc[-3]['close']\n",
    "            d_cvae_temp['low'] = d_cvae_temp['low'] + df.iloc[-3]['close']\n",
    "            d_baseline[ticker][date], d_cvae[ticker][date] = d_base_temp, d_cvae_temp\n",
    "        dill.dump(d_baseline,open(NN_PREDICTIONS_PATH,'wb'))\n",
    "        dill.dump(d_cvae,open(CVAE_PREDICTIONS_PATH,'wb'))\n",
    "    return d_baseline, d_cvae\n",
    "\n",
    "get_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_all_EOD = dill.load(open('d_all_EOD.pkd','rb'))\n",
    "for ticker in d_all_EOD.keys():\n",
    "    d_all_EOD[ticker] = d_all_EOD[ticker].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_low(ticker, date):\n",
    "    df_truth = d_all_EOD[ticker]\n",
    "    df1 = df_truth[df_truth.date==date]\n",
    "    index = df1.index[0]\n",
    "    return df_truth.iloc[index-1]['low']\n",
    "\n",
    "def find_high(ticker,date):\n",
    "    df_truth = d_all_EOD[ticker]\n",
    "    df1 = df_truth[df_truth.date==date]\n",
    "    index = df1.index[0]\n",
    "    return df_truth.iloc[index+1]['high']\n",
    "\n",
    "def calc_pe(prediction,true_value):\n",
    "    return 100*(prediction - true_value)/true_value\n",
    "\n",
    "def calc_ape(prediction,true_value):\n",
    "    return 100*np.abs(prediction - true_value)/true_value\n",
    "    \n",
    "def calc_mpe(d):\n",
    "    l_temp =[]\n",
    "    for ticker, dates in d.items():\n",
    "        for date, df in dates.items():\n",
    "            true_low = find_low(ticker,date)\n",
    "            true_high = find_high(ticker,date)\n",
    "            l_temp.append({'date': date, 'ticker': ticker,\n",
    "                        'pe_low': calc_pe(d[ticker][date]['low'], true_low), \n",
    "                        'pe_high': calc_pe(d[ticker][date]['high'], true_high),\n",
    "                        'ape_low': calc_ape(d[ticker][date]['low'], true_low),\n",
    "                        'ape_high': calc_ape(d[ticker][date]['high'], true_high)})\n",
    "    df_results = pd.DataFrame(l_temp)\n",
    "    \n",
    "    print('MPE Low:',df_results.pe_low.mean())\n",
    "    print('MPE High:',df_results.pe_high.mean())\n",
    "    print('MPE Overall:',df_results[['pe_low','pe_high']].mean()[0])\n",
    "    print('MAPE Low:',df_results.ape_low.mean())\n",
    "    print('MAPE High:',df_results.ape_high.mean())\n",
    "    print('MAPE Overall:',df_results[['ape_low','ape_high']].mean()[0])\n",
    "    \n",
    "    return df_results.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "def show_results(predictions_path):\n",
    "    df = calc_mpe(dill.load(open(predictions_path,'rb')))\n",
    "    return alt.Chart(df,title='PE for Low and High').mark_line().encode(x='date',y='pe_low')&\\\n",
    "alt.Chart(df).mark_line().encode(x='date',y='pe_high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPE Low: 0.26649749587839533\n",
      "MPE High: 1.308410868631888\n",
      "MPE Overall: 0.26649749587839533\n",
      "MAPE Low: 11.110435064831796\n",
      "MAPE High: 10.819459501604603\n",
      "MAPE Overall: 11.110435064831796\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>pe_low</th>\n",
       "      <th>pe_high</th>\n",
       "      <th>ape_low</th>\n",
       "      <th>ape_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>COST</td>\n",
       "      <td>0.428479</td>\n",
       "      <td>0.795573</td>\n",
       "      <td>0.428479</td>\n",
       "      <td>0.795573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>CE</td>\n",
       "      <td>35.988745</td>\n",
       "      <td>37.428411</td>\n",
       "      <td>35.988745</td>\n",
       "      <td>37.428411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>AON</td>\n",
       "      <td>6.999822</td>\n",
       "      <td>3.847648</td>\n",
       "      <td>6.999822</td>\n",
       "      <td>3.847648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>MKTX</td>\n",
       "      <td>31.534554</td>\n",
       "      <td>37.653688</td>\n",
       "      <td>31.534554</td>\n",
       "      <td>37.653688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>CAG</td>\n",
       "      <td>-8.182047</td>\n",
       "      <td>-5.466881</td>\n",
       "      <td>8.182047</td>\n",
       "      <td>5.466881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>CE</td>\n",
       "      <td>-3.980177</td>\n",
       "      <td>-2.741801</td>\n",
       "      <td>3.980177</td>\n",
       "      <td>2.741801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>TXN</td>\n",
       "      <td>12.980791</td>\n",
       "      <td>15.161332</td>\n",
       "      <td>12.980791</td>\n",
       "      <td>15.161332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>AON</td>\n",
       "      <td>2.069366</td>\n",
       "      <td>0.629494</td>\n",
       "      <td>2.069366</td>\n",
       "      <td>0.629494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>CAG</td>\n",
       "      <td>19.834266</td>\n",
       "      <td>20.421203</td>\n",
       "      <td>19.834266</td>\n",
       "      <td>20.421203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>COST</td>\n",
       "      <td>-6.265329</td>\n",
       "      <td>-6.996219</td>\n",
       "      <td>6.265329</td>\n",
       "      <td>6.996219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date ticker     pe_low    pe_high    ape_low   ape_high\n",
       "0   2022-10-27   COST   0.428479   0.795573   0.428479   0.795573\n",
       "1   2022-10-28     CE  35.988745  37.428411  35.988745  37.428411\n",
       "2   2022-10-31    AON   6.999822   3.847648   6.999822   3.847648\n",
       "3   2022-11-01   MKTX  31.534554  37.653688  31.534554  37.653688\n",
       "4   2022-11-02    CAG  -8.182047  -5.466881   8.182047   5.466881\n",
       "..         ...    ...        ...        ...        ...        ...\n",
       "228 2023-10-27     CE  -3.980177  -2.741801   3.980177   2.741801\n",
       "229 2023-10-30    TXN  12.980791  15.161332  12.980791  15.161332\n",
       "230 2023-10-31    AON   2.069366   0.629494   2.069366   0.629494\n",
       "231 2023-11-01    CAG  19.834266  20.421203  19.834266  20.421203\n",
       "232 2023-11-02   COST  -6.265329  -6.996219   6.265329   6.996219\n",
       "\n",
       "[233 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_results(predictions_path):\n",
    "    df = calc_mpe(dill.load(open(predictions_path,'rb')))\n",
    "    return df\n",
    "    return alt.Chart(df,title='PE for Low and High').mark_line().encode(x='date',y='pe_low')&\\\n",
    "alt.Chart(df).mark_line().encode(x='date',y='pe_high')\n",
    "show_results(CVAE_PREDICTIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPE Low: -0.02747839168538977\n",
      "MPE High: 0.17822576912126167\n",
      "MPE Overall: -0.02747839168538977\n",
      "MAPE Low: 1.3738052390573643\n",
      "MAPE High: 1.4044952845786483\n",
      "MAPE Overall: 1.3738052390573643\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>pe_low</th>\n",
       "      <th>pe_high</th>\n",
       "      <th>ape_low</th>\n",
       "      <th>ape_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>COST</td>\n",
       "      <td>-2.316935</td>\n",
       "      <td>-2.385948</td>\n",
       "      <td>2.316935</td>\n",
       "      <td>2.385948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>CE</td>\n",
       "      <td>-3.765026</td>\n",
       "      <td>-1.586693</td>\n",
       "      <td>3.765026</td>\n",
       "      <td>1.586693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>AON</td>\n",
       "      <td>2.364395</td>\n",
       "      <td>0.108482</td>\n",
       "      <td>2.364395</td>\n",
       "      <td>0.108482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>MKTX</td>\n",
       "      <td>-1.687145</td>\n",
       "      <td>2.896229</td>\n",
       "      <td>1.687145</td>\n",
       "      <td>2.896229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>CAG</td>\n",
       "      <td>-1.800977</td>\n",
       "      <td>0.142651</td>\n",
       "      <td>1.800977</td>\n",
       "      <td>0.142651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>CE</td>\n",
       "      <td>-0.573907</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.573907</td>\n",
       "      <td>0.018331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>TXN</td>\n",
       "      <td>1.056100</td>\n",
       "      <td>1.641190</td>\n",
       "      <td>1.056100</td>\n",
       "      <td>1.641190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>AON</td>\n",
       "      <td>1.071851</td>\n",
       "      <td>-0.952381</td>\n",
       "      <td>1.071851</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>CAG</td>\n",
       "      <td>-0.800431</td>\n",
       "      <td>-0.515535</td>\n",
       "      <td>0.800431</td>\n",
       "      <td>0.515535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>COST</td>\n",
       "      <td>-0.098564</td>\n",
       "      <td>-0.123006</td>\n",
       "      <td>0.098564</td>\n",
       "      <td>0.123006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date ticker    pe_low   pe_high   ape_low  ape_high\n",
       "0   2022-10-27   COST -2.316935 -2.385948  2.316935  2.385948\n",
       "1   2022-10-28     CE -3.765026 -1.586693  3.765026  1.586693\n",
       "2   2022-10-31    AON  2.364395  0.108482  2.364395  0.108482\n",
       "3   2022-11-01   MKTX -1.687145  2.896229  1.687145  2.896229\n",
       "4   2022-11-02    CAG -1.800977  0.142651  1.800977  0.142651\n",
       "..         ...    ...       ...       ...       ...       ...\n",
       "228 2023-10-27     CE -0.573907  0.018331  0.573907  0.018331\n",
       "229 2023-10-30    TXN  1.056100  1.641190  1.056100  1.641190\n",
       "230 2023-10-31    AON  1.071851 -0.952381  1.071851  0.952381\n",
       "231 2023-11-01    CAG -0.800431 -0.515535  0.800431  0.515535\n",
       "232 2023-11-02   COST -0.098564 -0.123006  0.098564  0.123006\n",
       "\n",
       "[233 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_results(predictions_path):\n",
    "    df = calc_mpe(dill.load(open(predictions_path,'rb')))\n",
    "    return df\n",
    "    return alt.Chart(df,title='PE for Low and High').mark_line().encode(x='date',y='pe_low')&\\\n",
    "alt.Chart(df).mark_line().encode(x='date',y='pe_high')\n",
    "show_results(NN_PREDICTIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>adjHigh</th>\n",
       "      <th>adjLow</th>\n",
       "      <th>adjOpen</th>\n",
       "      <th>adjVolume</th>\n",
       "      <th>divCash</th>\n",
       "      <th>splitFactor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>113.33</td>\n",
       "      <td>113.390</td>\n",
       "      <td>111.5100</td>\n",
       "      <td>112.37</td>\n",
       "      <td>118857369</td>\n",
       "      <td>91.426173</td>\n",
       "      <td>91.474576</td>\n",
       "      <td>89.957933</td>\n",
       "      <td>90.651716</td>\n",
       "      <td>118857369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>113.63</td>\n",
       "      <td>113.680</td>\n",
       "      <td>112.8500</td>\n",
       "      <td>113.26</td>\n",
       "      <td>111519230</td>\n",
       "      <td>91.668190</td>\n",
       "      <td>91.708526</td>\n",
       "      <td>91.038944</td>\n",
       "      <td>91.369702</td>\n",
       "      <td>111519230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>113.71</td>\n",
       "      <td>113.990</td>\n",
       "      <td>113.4300</td>\n",
       "      <td>113.52</td>\n",
       "      <td>116017127</td>\n",
       "      <td>91.732728</td>\n",
       "      <td>91.958611</td>\n",
       "      <td>91.506845</td>\n",
       "      <td>91.579450</td>\n",
       "      <td>116017127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>114.19</td>\n",
       "      <td>114.330</td>\n",
       "      <td>113.1800</td>\n",
       "      <td>113.50</td>\n",
       "      <td>130502017</td>\n",
       "      <td>92.119956</td>\n",
       "      <td>92.232898</td>\n",
       "      <td>91.305164</td>\n",
       "      <td>91.563316</td>\n",
       "      <td>130502017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>114.57</td>\n",
       "      <td>114.620</td>\n",
       "      <td>113.6600</td>\n",
       "      <td>113.89</td>\n",
       "      <td>126357911</td>\n",
       "      <td>92.426512</td>\n",
       "      <td>92.466848</td>\n",
       "      <td>91.692392</td>\n",
       "      <td>91.877939</td>\n",
       "      <td>126357911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>415.59</td>\n",
       "      <td>416.680</td>\n",
       "      <td>412.2200</td>\n",
       "      <td>413.56</td>\n",
       "      <td>86562675</td>\n",
       "      <td>415.590000</td>\n",
       "      <td>416.680000</td>\n",
       "      <td>412.220000</td>\n",
       "      <td>413.560000</td>\n",
       "      <td>86562675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>418.20</td>\n",
       "      <td>418.530</td>\n",
       "      <td>414.2100</td>\n",
       "      <td>416.18</td>\n",
       "      <td>79665150</td>\n",
       "      <td>418.200000</td>\n",
       "      <td>418.530000</td>\n",
       "      <td>414.210000</td>\n",
       "      <td>416.180000</td>\n",
       "      <td>79665150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>422.66</td>\n",
       "      <td>423.500</td>\n",
       "      <td>418.6499</td>\n",
       "      <td>419.20</td>\n",
       "      <td>98068115</td>\n",
       "      <td>422.660000</td>\n",
       "      <td>423.500000</td>\n",
       "      <td>418.649900</td>\n",
       "      <td>419.200000</td>\n",
       "      <td>98068115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>430.76</td>\n",
       "      <td>430.915</td>\n",
       "      <td>426.5600</td>\n",
       "      <td>426.58</td>\n",
       "      <td>94938909</td>\n",
       "      <td>430.760000</td>\n",
       "      <td>430.915000</td>\n",
       "      <td>426.560000</td>\n",
       "      <td>426.580000</td>\n",
       "      <td>94938909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>434.69</td>\n",
       "      <td>436.290</td>\n",
       "      <td>433.0100</td>\n",
       "      <td>433.14</td>\n",
       "      <td>100167775</td>\n",
       "      <td>434.690000</td>\n",
       "      <td>436.290000</td>\n",
       "      <td>433.010000</td>\n",
       "      <td>433.140000</td>\n",
       "      <td>100167775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3484 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   close     high       low    open     volume    adjClose  \\\n",
       "0    2010-01-04  113.33  113.390  111.5100  112.37  118857369   91.426173   \n",
       "1    2010-01-05  113.63  113.680  112.8500  113.26  111519230   91.668190   \n",
       "2    2010-01-06  113.71  113.990  113.4300  113.52  116017127   91.732728   \n",
       "3    2010-01-07  114.19  114.330  113.1800  113.50  130502017   92.119956   \n",
       "4    2010-01-08  114.57  114.620  113.6600  113.89  126357911   92.426512   \n",
       "...         ...     ...      ...       ...     ...        ...         ...   \n",
       "3479 2023-10-30  415.59  416.680  412.2200  413.56   86562675  415.590000   \n",
       "3480 2023-10-31  418.20  418.530  414.2100  416.18   79665150  418.200000   \n",
       "3481 2023-11-01  422.66  423.500  418.6499  419.20   98068115  422.660000   \n",
       "3482 2023-11-02  430.76  430.915  426.5600  426.58   94938909  430.760000   \n",
       "3483 2023-11-03  434.69  436.290  433.0100  433.14  100167775  434.690000   \n",
       "\n",
       "         adjHigh      adjLow     adjOpen  adjVolume  divCash  splitFactor  \n",
       "0      91.474576   89.957933   90.651716  118857369      0.0          1.0  \n",
       "1      91.708526   91.038944   91.369702  111519230      0.0          1.0  \n",
       "2      91.958611   91.506845   91.579450  116017127      0.0          1.0  \n",
       "3      92.232898   91.305164   91.563316  130502017      0.0          1.0  \n",
       "4      92.466848   91.692392   91.877939  126357911      0.0          1.0  \n",
       "...          ...         ...         ...        ...      ...          ...  \n",
       "3479  416.680000  412.220000  413.560000   86562675      0.0          1.0  \n",
       "3480  418.530000  414.210000  416.180000   79665150      0.0          1.0  \n",
       "3481  423.500000  418.649900  419.200000   98068115      0.0          1.0  \n",
       "3482  430.915000  426.560000  426.580000   94938909      0.0          1.0  \n",
       "3483  436.290000  433.010000  433.140000  100167775      0.0          1.0  \n",
       "\n",
       "[3484 rows x 13 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = d_all_EOD['SPY']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "((df['high'] - df['close'].shift(fill_value=0))/df['high']).iloc[1:].hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': '0'}>]], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(MinMaxScaler().fit(df['high'].values.reshape(-1,1)).transform(df['high'].values.reshape(-1,1))).hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
