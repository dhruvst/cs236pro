{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import Compose, functional\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import dill\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
    "from pyro.infer import Predictive, Trace_ELBO\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with z sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 5\n",
    "Z_DIM = 10\n",
    "INPUT_SHAPE = [8,3]\n",
    "DATA_PATH ='data/d_dfs.pkd'\n",
    "NN_PREDICTIONS_PATH = 'data/predictions_baseline83_z10.pkd'\n",
    "CVAE_PREDICTIONS_PATH = 'data/predictions_cvae83_z10.pkd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STOCK(Dataset):\n",
    "    def __init__(self, pd_df, input_size = INPUT_SIZE, mask_size=3, train = True):\n",
    "        self.original, self.test_low, self.test_high, self.minmax = self.loadData(pd_df, input_size, mask_size)\n",
    "        self.transform =  Compose([ToTensor(), MaskData(pos=mask_size)])\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sample = {\"original\":self.original[item]}\n",
    "        test_low = {\"original\":self.test_low[0]}\n",
    "        test_high = {\"original\":self.test_high[0]}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            test_low = self.transform(test_low)\n",
    "            test_high = self.transform(test_high)\n",
    "        if self.train:\n",
    "            return sample\n",
    "        else:\n",
    "            return {'input_low': test_low['input'], 'input_high': test_high['input']}\n",
    "    \n",
    "    def loadData(self, df, input_size, mask_size):\n",
    "    \n",
    "        minmax = MinMaxScaler().fit(df.values.reshape(-1,3))\n",
    "        df_norm = pd.DataFrame(minmax.transform(df.values.reshape(-1,3)))\n",
    "        \n",
    "        df_norm.index = df.index\n",
    "        df_norm.columns = df.columns\n",
    "\n",
    "        dataset = []\n",
    "        for i in range(len(df_norm) - (input_size+mask_size) - 1):\n",
    "            dataset.append(df_norm.iloc[i:i + (input_size+mask_size),:])\n",
    "        \n",
    "        testset_low = [df_norm.iloc[-(input_size+mask_size+1) : -1]]\n",
    "        testset_high = [df_norm.iloc[-input_size : ].append(pd.DataFrame([{'close':0,'high':0,'low':0}]*mask_size))]\n",
    "\n",
    "        return dataset, testset_low, testset_high, minmax\n",
    "    \n",
    "    def reverseMinMax(self, pred):\n",
    "        return self.minmax.inverse_transform(pred)\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        sample['original'] = torch.from_numpy(sample['original'].values).float()\n",
    "        return sample\n",
    "\n",
    "class MaskData:\n",
    "    \"\"\"This transformation masks the values to be predicted with -1 and\n",
    "    adds the target output in the sample dict as the complementary of the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pos=1, mask_with=-1):\n",
    "        self.mask_with = mask_with\n",
    "        self.pos = -pos\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        tensor = sample['original']\n",
    "        inp = tensor.detach().clone()\n",
    "\n",
    "        # remove the last one\n",
    "        inp[self.pos:] = self.mask_with\n",
    "\n",
    "        # now, sets the input as complementary\n",
    "        out = tensor.clone()\n",
    "        out[inp != -1] = self.mask_with\n",
    "\n",
    "        sample[\"input\"] = inp\n",
    "        sample[\"output\"] = out\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, batch_size=16):\n",
    "    data, dl, ds = {}, {}, {}\n",
    "    data['train'] = STOCK(df)\n",
    "    data['test'] = STOCK(df, train = False)\n",
    "    dl['train'] = DataLoader(data['train'], batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    dl['val'] = DataLoader(data['train'], batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    ds['train'] = ds['val'] = len(dl['train'])\n",
    "    return data, dl, ds\n",
    "\n",
    "def get_all_data(filepath = DATA_PATH):\n",
    "    datasets, dataloaders, dataset_sizes = defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "    d_all = pd.read_pickle(filepath)\n",
    "    for ticker, dates in d_all.items():    \n",
    "        for date,df in dates.items():\n",
    "            datasets[ticker][date], dataloaders[ticker][date], dataset_sizes[ticker][date] = get_data(df)\n",
    "    return datasets, dataloaders, dataset_sizes\n",
    "datasets, dataloaders, dataset_sizes = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': tensor([[0.2966, 0.2599, 0.3259],\n",
       "         [0.2870, 0.2509, 0.3161],\n",
       "         [0.2515, 0.2357, 0.2950],\n",
       "         [0.3223, 0.2765, 0.2917],\n",
       "         [0.4203, 0.3770, 0.3896],\n",
       "         [0.4312, 0.3889, 0.4392]]),\n",
       " 'input': tensor([[ 0.2966,  0.2599,  0.3259],\n",
       "         [ 0.2870,  0.2509,  0.3161],\n",
       "         [ 0.2515,  0.2357,  0.2950],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]]),\n",
       " 'output': tensor([[-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [ 0.3223,  0.2765,  0.2917],\n",
       "         [ 0.4203,  0.3770,  0.3896],\n",
       "         [ 0.4312,  0.3889,  0.4392]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['COST'][datetime(2022, 10, 27)]['train'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_low': tensor([[ 0.2870,  0.2509,  0.3161],\n",
       "         [ 0.2515,  0.2357,  0.2950],\n",
       "         [ 0.3223,  0.2765,  0.2917],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]]),\n",
       " 'input_high': tensor([[ 0.4312,  0.3889,  0.4392],\n",
       "         [ 0.4333,  0.4284,  0.4664],\n",
       "         [ 0.4181,  0.4043,  0.4583],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['COST'][datetime(2022, 10, 27)]['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, hidden_1, hidden_2, input_shape=INPUT_SHAPE):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(np.prod(input_shape), hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, np.prod(input_shape))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, np.prod(self.input_shape))\n",
    "        hidden = self.relu(self.fc1(x))\n",
    "        hidden = self.relu(self.fc2(hidden))\n",
    "        y = torch.sigmoid(self.fc3(hidden))\n",
    "        return y\n",
    "\n",
    "\n",
    "class MaskedMSELoss(nn.Module):\n",
    "    def __init__(self, masked_with=-1):\n",
    "        super().__init__()\n",
    "        self.masked_with = masked_with\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        target = target.view(input.shape)\n",
    "        loss = F.mse_loss(input, target, reduction=\"none\")\n",
    "        loss[target == self.masked_with] = 0\n",
    "        return loss.sum()\n",
    "\n",
    "\n",
    "def train_baseline(\n",
    "    device,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    learning_rate,\n",
    "    num_epochs,\n",
    "    early_stop_patience,\n",
    "    model_path=None,\n",
    "    input_shape = INPUT_SHAPE\n",
    "):\n",
    "    # Train baseline\n",
    "    baseline_net = BaselineNet(500, 500,input_shape=input_shape)\n",
    "    baseline_net.to(device)\n",
    "    optimizer = torch.optim.Adam(baseline_net.parameters(), lr=learning_rate)\n",
    "    criterion = MaskedMSELoss()\n",
    "    best_loss = np.inf\n",
    "    early_stop_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                baseline_net.train()\n",
    "            else:\n",
    "                baseline_net.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            num_preds = 0\n",
    "\n",
    "            #bar = tqdm(dataloaders[phase], desc=\"NN Epoch {} {}\".format(epoch, phase).ljust(20)\n",
    "\n",
    "            #for i, batch in enumerate(bar):\n",
    "            for batch in dataloaders[phase]:#don't want 100 epoch bars for each of hundreds of models\n",
    "                inputs = batch[\"input\"].to(device)\n",
    "                outputs = batch[\"output\"].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    preds = baseline_net(inputs)\n",
    "                    loss = criterion(preds, outputs) / inputs.size(0)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                num_preds += 1\n",
    "                #if i % 10 == 0:\n",
    "                #    bar.set_postfix(\n",
    "                #        loss=\"{:.2f}\".format(running_loss / num_preds),\n",
    "                #        early_stop_count=early_stop_count,\n",
    "                #    )\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # deep copy the model\n",
    "            if phase == \"val\":\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(baseline_net.state_dict())\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= early_stop_patience:\n",
    "            break\n",
    "\n",
    "    baseline_net.load_state_dict(best_model_wts)\n",
    "    baseline_net.eval()\n",
    "\n",
    "    # Save model weights\n",
    "    #Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    #torch.save(baseline_net.state_dict(), model_path)\n",
    "\n",
    "    return baseline_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_net = train_baseline(device=torch.device(\n",
    "        \"cuda:0\" if torch.cuda.is_available() and args.cuda else \"cpu\"),\n",
    "            dataloaders=dataloaders['COST'][datetime(2022, 10, 27)],\n",
    "            dataset_sizes=dataset_sizes['COST'][datetime(2022, 10, 27)],\n",
    "            learning_rate=1.0e-3,\n",
    "            num_epochs=101,\n",
    "            early_stop_patience=20,\n",
    "            model_path=\"baseline_net.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceGraph_ELBO\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_1, hidden_2, input_shape=INPUT_SHAPE):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(np.prod(input_shape), hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc31 = nn.Linear(hidden_2, z_dim)\n",
    "        self.fc32 = nn.Linear(hidden_2, z_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # put x and y together in the same tensor for simplification\n",
    "        xc = x.clone()\n",
    "        xc[x == -1] = y[x == -1]\n",
    "        xc = xc.view(-1, np.prod(self.input_shape))\n",
    "        # then compute the hidden units\n",
    "        hidden = self.relu(self.fc1(xc))\n",
    "        hidden = self.relu(self.fc2(hidden))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc31(hidden)\n",
    "        z_scale = torch.exp(self.fc32(hidden))\n",
    "        return z_loc, z_scale\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_1, hidden_2,  input_shape=INPUT_SHAPE):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, np.prod(input_shape))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, z):\n",
    "        y = self.relu(self.fc1(z))\n",
    "        y = self.relu(self.fc2(y))\n",
    "        #y = self.fc3(y)\n",
    "        y = torch.sigmoid(self.fc3(y))\n",
    "        return y\n",
    "\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_1, hidden_2, pre_trained_baseline_net,  input_shape=INPUT_SHAPE):\n",
    "        super().__init__()\n",
    "        # The CVAE is composed of multiple MLPs, such as recognition network\n",
    "        # qφ(z|x, y), (conditional) prior network pθ(z|x), and generation\n",
    "        # network pθ(y|x, z). Also, CVAE is built on top of the NN: not only\n",
    "        # the direct input x, but also the initial guess y_hat made by the NN\n",
    "        # are fed into the prior network.\n",
    "        self.baseline_net = pre_trained_baseline_net\n",
    "        self.prior_net = Encoder(z_dim, hidden_1, hidden_2)\n",
    "        self.generation_net = Decoder(z_dim, hidden_1, hidden_2)\n",
    "        self.recognition_net = Encoder(z_dim, hidden_1, hidden_2)\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def model(self, xs, ys=None):\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"generation_net\", self)\n",
    "        batch_size = xs.shape[0]\n",
    "\n",
    "        with pyro.plate(\"data\"):\n",
    "            # Prior network uses the baseline predictions as initial guess.\n",
    "            # This is the generative process with recurrent connection\n",
    "            with torch.no_grad():\n",
    "                # this ensures the training process does not change the\n",
    "                # baseline network\n",
    "                y_hat = self.baseline_net(xs).view(xs.shape)\n",
    "\n",
    "            # sample the handwriting style from the prior distribution, which is\n",
    "            # modulated by the input xs.\n",
    "            prior_loc, prior_scale = self.prior_net(xs, y_hat)\n",
    "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
    "\n",
    "            # the output y is generated from the distribution pθ(y|x, z)\n",
    "            loc = self.generation_net(zs)\n",
    "\n",
    "            if ys is not None:\n",
    "                # In training, we will only sample in the masked image\n",
    "                mask_loc = loc[(xs == -1).view(-1, np.prod(self.input_shape))].view(batch_size, -1)\n",
    "                mask_ys = ys[xs == -1].view(batch_size, -1)\n",
    "                \n",
    "                pyro.deterministic(\"y\", loc)\n",
    "\n",
    "            else:\n",
    "                # In testing, no need to sample: the output is already a\n",
    "                # probability in [0, 1] range, which better represent pixel\n",
    "                # values considering grayscale. If we sample, we will force\n",
    "                # each pixel to be  either 0 or 1, killing the grayscale\n",
    "                pyro.deterministic(\"y\", loc.detach())\n",
    "\n",
    "            # return the loc so we can visualize it later\n",
    "            return loc\n",
    "\n",
    "    def guide(self, xs, ys=None):\n",
    "        with pyro.plate(\"data\"):\n",
    "            if ys is None:\n",
    "                # at inference time, ys is not provided. In that case,\n",
    "                # the model uses the prior network\n",
    "                y_hat = self.baseline_net(xs).view(xs.shape)\n",
    "                loc, scale = self.prior_net(xs, y_hat)\n",
    "            else:\n",
    "                # at training time, uses the variational distribution\n",
    "                # q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
    "                loc, scale = self.recognition_net(xs, ys)\n",
    "            \n",
    "            pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
    "\n",
    "\n",
    "def train_cvae(\n",
    "    device,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    learning_rate,\n",
    "    num_epochs,\n",
    "    early_stop_patience,\n",
    "    model_path=\"cvae_net1.pth\",\n",
    "    pre_trained_baseline_net=baseline_net,\n",
    "):\n",
    "    # clear param store\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    cvae_net = CVAE(Z_DIM, 500, 500, pre_trained_baseline_net)\n",
    "    cvae_net.to(device)\n",
    "    optimizer = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "    svi = SVI(cvae_net.model, cvae_net.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "    best_loss = np.inf\n",
    "    early_stop_count = 0\n",
    "    Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            running_loss = 0.0\n",
    "            num_preds = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            #bar = tqdm(\n",
    "            #    dataloaders[phase],\n",
    "            #    desc=\"CVAE Epoch {} {}\".format(epoch, phase).ljust(20))\n",
    "            #for i,batch in enumerate(bar):\n",
    "            for batch in dataloaders[phase]:#don't want epoch bars for hundreds of models\n",
    "                inputs = batch[\"input\"].to(device)\n",
    "                outputs = batch[\"output\"].to(device)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss = svi.step(inputs, outputs)\n",
    "                else:\n",
    "                    loss = svi.evaluate_loss(inputs, outputs)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss / inputs.size(0)\n",
    "                num_preds += 1\n",
    "                #if i % 10 == 0:\n",
    "                #    bar.set_postfix(\n",
    "                #        loss=\"{:.2f}\".format(running_loss / num_preds),\n",
    "                #        early_stop_count=early_stop_count)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # deep copy the model\n",
    "            if phase == \"val\":\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    torch.save(cvae_net.state_dict(), model_path)\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= early_stop_patience:\n",
    "            break\n",
    "\n",
    "    # Save model weights\n",
    "    cvae_net.load_state_dict(torch.load(model_path))\n",
    "    cvae_net.eval()\n",
    "    return cvae_net\n",
    "\n",
    "cvae_net = train_cvae(\n",
    "            device=torch.device(\n",
    "        \"cuda:0\" if torch.cuda.is_available() and args.cuda else \"cpu\"),\n",
    "            dataloaders=dataloaders['COST'][datetime(2022, 10, 27)],\n",
    "            dataset_sizes=dataset_sizes['COST'][datetime(2022, 10, 27)],\n",
    "            learning_rate=1.0e-3,\n",
    "            num_epochs=101,\n",
    "            early_stop_patience=20,\n",
    "            model_path=\"cvae_net1.pth\",\n",
    "            pre_trained_baseline_net=baseline_net,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COST 2022-10-27 00:00:00\n",
      "COST 2023-02-02 00:00:00\n",
      "COST 2023-05-04 00:00:00\n",
      "COST 2023-08-24 00:00:00\n",
      "COST 2023-11-02 00:00:00\n",
      "CE 2022-10-28 00:00:00\n",
      "CE 2023-07-28 00:00:00\n",
      "CE 2023-10-27 00:00:00\n",
      "AON 2022-10-31 00:00:00\n",
      "AON 2023-01-31 00:00:00\n",
      "AON 2023-04-28 00:00:00\n",
      "AON 2023-07-31 00:00:00\n",
      "AON 2023-10-31 00:00:00\n",
      "MKTX 2022-11-01 00:00:00\n",
      "MKTX 2023-02-07 00:00:00\n",
      "MKTX 2023-05-09 00:00:00\n",
      "MKTX 2023-08-01 00:00:00\n",
      "CAG 2022-11-02 00:00:00\n",
      "CAG 2023-11-01 00:00:00\n",
      "NSC 2022-11-03 00:00:00\n",
      "NSC 2023-08-03 00:00:00\n",
      "AMP 2022-11-04 00:00:00\n",
      "AMP 2023-02-09 00:00:00\n",
      "AMP 2023-08-04 00:00:00\n",
      "AWK 2022-11-07 00:00:00\n",
      "AWK 2023-02-06 00:00:00\n",
      "AWK 2023-05-08 00:00:00\n",
      "AWK 2023-08-07 00:00:00\n",
      "WST 2022-11-08 00:00:00\n",
      "WST 2023-01-24 00:00:00\n",
      "WST 2023-04-25 00:00:00\n",
      "WST 2023-07-25 00:00:00\n",
      "POOL 2022-11-09 00:00:00\n",
      "POOL 2023-05-16 00:00:00\n",
      "POOL 2023-08-09 00:00:00\n",
      "GWW 2022-11-10 00:00:00\n",
      "GWW 2023-02-10 00:00:00\n",
      "GWW 2023-05-05 00:00:00\n",
      "GWW 2023-08-11 00:00:00\n",
      "TFX 2022-11-14 00:00:00\n",
      "TFX 2023-03-02 00:00:00\n",
      "TFX 2023-08-14 00:00:00\n",
      "EQIX 2022-11-15 00:00:00\n",
      "EQIX 2023-05-23 00:00:00\n",
      "EQIX 2023-08-22 00:00:00\n",
      "AMGN 2022-11-16 00:00:00\n",
      "AMGN 2023-05-17 00:00:00\n",
      "WHR 2022-11-17 00:00:00\n",
      "WHR 2023-05-18 00:00:00\n",
      "TSCO 2022-11-18 00:00:00\n",
      "SWKS 2022-11-21 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def train_predict(ticker, date\n",
    "        , device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), mask_shape=[INPUT_SIZE,3]):\n",
    "    d_baseline, d_cvae = {}, {}\n",
    "    dataset = datasets[ticker][date]\n",
    "    dataloader_test = DataLoader(dataset[\"test\"], batch_size=1, shuffle=False)\n",
    "    batch = next(iter(dataloader_test))\n",
    "    \n",
    "    def get_pred(model, input_type, prelim_high_prediction=False):\n",
    "        ### input_type: input_low or input_high\n",
    "        prediction = model(batch[input_type].to(device))\n",
    "        if type(prediction) == dict:\n",
    "            prediction = prediction['y']\n",
    "        prediction = prediction.reshape(-1,3).detach()\n",
    "        prediction = torch.from_numpy(dataset['test'].reverseMinMax(prediction))\n",
    "        index = {'input_low':2, 'input_high':1}\n",
    "        if input_type == 'input_low' and prelim_high_prediction:\n",
    "            return prediction[mask_shape[0], index['input_low']].item()\\\n",
    "                    , prediction[mask_shape[0]+mask_shape[1]-1, index['input_high']].item()\n",
    "        return prediction[mask_shape[0], index[input_type]].item(),0\n",
    "    \n",
    "    baseline_net = train_baseline(device=device,\n",
    "            dataloaders=dataloaders[ticker][date],\n",
    "            dataset_sizes=dataset_sizes[ticker][date],\n",
    "            learning_rate=1.0e-3,\n",
    "            num_epochs=101,\n",
    "            early_stop_patience=20, input_shape=(sum(mask_shape), 3))\n",
    "\n",
    "    d_baseline['low'], d_baseline['estimated_high'] = get_pred(baseline_net, 'input_low', prelim_high_prediction = True)\n",
    "    d_baseline['high'] = get_pred(baseline_net, 'input_high')[0]\n",
    "    \n",
    "    cvae_net = train_cvae(device,\n",
    "            dataloaders=dataloaders[ticker][date],\n",
    "            dataset_sizes=dataset_sizes[ticker][date],\n",
    "            learning_rate=1.0e-3,\n",
    "            num_epochs=101,\n",
    "            early_stop_patience=20,\n",
    "            pre_trained_baseline_net=baseline_net,)\n",
    "    predictive = Predictive(cvae_net.model, guide=cvae_net.guide, num_samples=1)\n",
    "\n",
    "    d_cvae['low'], d_cvae['estimated_high'] = get_pred(predictive, 'input_low' , prelim_high_prediction = True)\n",
    "    d_cvae['high'] = get_pred(predictive, 'input_high')[0]\n",
    "\n",
    "    return d_baseline,d_cvae\n",
    "\n",
    "def get_predictions():\n",
    "    d_all = pd.read_pickle(DATA_PATH)\n",
    "    d_baseline, d_cvae = defaultdict(dict), defaultdict(dict)\n",
    "    for ticker, dates in d_all.items():\n",
    "        for date,df in dates.items():\n",
    "            print(ticker,date)\n",
    "            d_baseline[ticker][date], d_cvae[ticker][date] = train_predict(ticker, date)\n",
    "        dill.dump(d_baseline,open(NN_PREDICTIONS_PATH,'wb'))\n",
    "        dill.dump(d_cvae,open(CVAE_PREDICTIONS_PATH,'wb'))\n",
    "    return d_baseline, d_cvae\n",
    "\n",
    "get_predictions()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
